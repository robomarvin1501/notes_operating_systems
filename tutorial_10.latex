\documentclass{article}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{blindtext}
\usepackage{multicol}
\usepackage{graphicx}
\usepackage{placeins}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{booktabs}
\usepackage{float}
\usepackage{listings}
\usepackage{bbm}
\usepackage{wrapfig}
\usepackage{color}
\usepackage[bookmarks=true]{hyperref}
\usepackage{bookmark}
\graphicspath{ {./images/} }
\usepackage[bottom=0.5cm, right=1.5cm, left=1.5cm, top=1.5cm]{geometry}

\newtheorem{theorem}{Theorem}
\newtheorem{exercise}{Exercise}
\newtheorem{example}{Example}
\newtheorem{definition}{Definition}[section]

\newcommand{\R}{\ensuremath{\mathbb{R}}}
\newcommand{\N}{\ensuremath{\mathbb{N}}}
\newcommand{\Z}{\ensuremath{\mathbb{Z}}}
\newcommand{\p}{\ensuremath{\mathbb{P}}}
\newcommand{\E}{\ensuremath{\mathbb{E}}}
\newcommand{\F}{\ensuremath{\mathcal{F}}}
\newcommand{\1}{\ensuremath{\mathbbm{1}}}
\newcommand{\B}{\ensuremath{\mathbbm{B}}}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=C,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

\title{Tutorial 10 - Memory management}
\author{Gidon Rosalki}
\date{2025-06-04}

\begin{document}
\maketitle
\noindent\textbf{Notice:} If you find any mistakes, please open an issue at \href{https://github.com/robomarvin1501/notes\_operating\_systems}{\texttt{https://github.com/robomarvin1501/notes\_operating\_systems}}
\section{Reminder}\label{sec:Reminder} % (fold)
The physical memory is the RAM, and the physical address is the address in the particular storage cell of the RAM. The
physical address space depends on the memory size, if we have 8GB or RAM, then the address length is 33 ($\log_2
\left(8GB\right)$). \\
Processes are generally unaware of the memory usage of other processes, or their own exact memory usage. Therefore, the
OS provides each process with a virtual address space, where the process has (almost) unlimited memory, and the process
thinks it is the only one that exists. The OS is responsible for mapping the virtual memory of each of the processes
into the physical memory. Usually the virtual memory of a single process is much larger than the actual physical memory.
2 processes may access the same logical (virtual) address, but the OS maps it to a different physical address. \\

The logical address space of process can be non-contiguous; a process is allocated physical memory whenever the latter
is available. Physical memory is partitioned into fixed-sized blocks called \textbf{frames}. Logical memory is
partitioned into blocks of the same size called \textbf{pages}. With paging, every time that process 1 runs, some of
its memory would be loaded, and other processes would be stored on the disk. The free frames are kept track of, and to
run a program of size $n$ pages, need to find $n$ free frames and load program. To do this, one sets up a page table to
translate logical to physical addresses. This way, we have avoided external fragmentation of the memory, however there
is still likely to be internal fragmentation (within the program that is).

The address generated by the CPU is divided into \begin{itemize}
    \item The \textbf{page number} $p$, used as an index into a page table, which contains the base address of each page
        in physical memory
    \item The \textbf{page offset} $d$, combined with base address to define the physical memory address that is sent to
        the memory unit
\end{itemize}
For a given logical address space of size $2^m$ words, and page size $2^n$ words, then the page number is of size $m -
n$ bits, and the page offset is $n$ bits. \\

As the number of processes increases, the percentage of memory devoted to page tables also increases. We discussed the
solution Hierarchical paging last week. This week,let us discuss \textit{Inverted Page Tables}.
% section Reminder (end)

\section{Inverted Page Tables}\label{sec:Inverted Page Tables} % (fold)
\subsection{Architecture}\label{sub:Architecture} % (fold)
There is one table with the size of the physical memory shared for all processes. Each entry consists of the virtual
address of the page stored in that real memory location, with information about the process that owns that page. This
decreases the memory needed to store each page table, but increases time needed to search the table when a page reference
occurs. It also doesn't map virtual addresses to non-existent physical addresses.
\begin{figure}[H]
    \center
    \includegraphics[scale=0.2]{tutorial_10_inverted_page_table_architecture}
    \caption{Inverted page table architecture}
\end{figure}

Generally, we use Hierarchical paging, rather than inverted page tables, since Hierarchical costs memory, but is very
fast ($O \left(1\right)$), whereas inverted page tables need less memory, but take much more time, and at the moment
memory is relatively cheap, and we want speed as much as possible. Since this linear search is so slow, in practice it
is usually implemented as an open hash table. The hash function maps the virtual page to a list of mappings,
$\text{page} \to \text{frame} $. The length of each list should be short.
% subsection Architecture (end)

% section Inverted Page Tables (end)

\section{TLB}\label{sec:TLB} % (fold)
\subsection{Limitations of page tables}\label{sub:Limitations of page tables} % (fold)
Mapping virtual addresses to physical memory adds overhead to every memory access. Even in 1-level paging, every
data/instruction access requires two memory accesses: one for the page table and one for the data/instruction. Due to
the described problems previously, it is often more than 2 accesses, for multi level paging. The CPU uses a cache of
recently used mappings from the operating system's page table. This cache is called the Translation look-aside buffers
(TLBs) which is an associative cache.
% subsection Limitations of page tables (end)

\pagebreak
\subsection{TLB}\label{sub:TLB} % (fold)
The TLB usually contains 64 entries, and some TLBs store \textbf{address-space identifiers} (ASIDs) in each TLB entry,
which uniquely identify each process to provide address-space protection for that process.
\begin{figure}[H]
    \center
    \includegraphics[scale=0.2]{tutorial_10_paging_with_tlb}
    \caption{Paging hardware with TLB}
\end{figure}
For more detail on TLBs, please see my notes in computer architecture (lectures 8 and 9).
\begin{figure}[H]
    \center
    \includegraphics[scale=0.2]{tutorial_10_address_translation}
    \caption{Address translation}
\end{figure}
\begin{figure}[H]
    \center
    \includegraphics[scale=0.2]{tutorial_10_TLB}
    \caption{TLB}
\end{figure}
% subsection TLB (end)

\subsection{Avoiding page faults}\label{sub:Avoiding page faults} % (fold)
Loading and evicting takes time, so we want to lower the page miss rate:

\subsubsection{Copy on Write}\label{sec:Copy on Write} % (fold)
One technique for lowering the page miss rate is CoW (Copy on Write). Let us assume that a process has duplicated itself
using \lstinline[columns=fixed]{fork()}. The duplicated process has an identical Virtual Address Space, and so there is
\textbf{no need} to copy the VAS for the child process, so long as no writes have been performed. Then, if one of the
processes writes something to one of its pages, \textit{then} this specific page will be duplicated and changed in
memory.
% subsubsection Copy on Write (end)
% subsection Avoiding page faults (end)
% section TLB (end)

\section{Exam questions}\label{sec:Exam questiosn} % (fold)
\subsection{1}\label{sub:1} % (fold)
Consider a machine with:
\begin{itemize}
    \item Physical memory of 8 GB
    \item Page size of 8 KB
    \item Page table entry size of 4 bytes
    \item Every Page table fits into a single page
\end{itemize}
How many levels of page tables would be required to map a 46-bit virtual address? \\

Given a page size of size $8KB$ we need a pointer of size $2^3 \cdot 2^{10} = 2^{13}$, so of size 13 bits. This is our
offset. That leaves us with $46 - 13 = 33$ bits. Each row is of size 4 bytes, and we have a table of size 13 bits, so we
have $13 - 2 = 11$ bits of entries. Since the next level up page table would be the same size, we will use 11 bits of
the remaining 22 to create a new page table, that is one level up from entries. Now we have 11 bits left, and we will
create a new page table, again of 11 bits, indexing the second level page table.

THIS IS A CLASSIC EXAM QUESTION, MAKE SURE THAT YOU KNOW HOW TO DO IT.
% subsection 1 (end)

\subsection{2}\label{sub:2} % (fold)
List the fields of a Page Table Entry (PTE) in your scheme: \\
Each PTE will have a pointer to the proper page, plus several bits, such as permissions, used, dirty, and valid bits.
This information can all fit into 4 bytes, since 20 bits are needed to point to the proper page, leaving 12 bits for the
information bits, which is ample space. \\
As explained in class: \\
We have $\displaystyle\frac{8GB}{8KB} = 2^{20}$ frames, since the number of frames is equal to the number of pages. We
have 4 bytes per frame, i.e. $2^4 = 32$ bits. We need 20 to point to the frames, thus leaving us with 12 bits, which
should be sufficient for the information bits (permissions, used, dirty, valid, etc.).
% subsection 2 (end)

\subsection{3}\label{sub:3} % (fold)
Without a cache, how many memory operations are required to read or write a single 32-bit word? (Words aren't split
between pages, they are sections of memory that are not split between pages). \\
4 - we have 3 page table lookups, and then the actual memory operation to get the data.
% subsection 3 (end)

\subsection{4}\label{sub:4} % (fold)
How much physical memory is needed (at least) for a process with 3 pages of virtual memory (for example, one code, one
data, and one stack)? \\
We need 3 frames for the process's 3 pages, 1 frame for the third level page table, 1 for the second level page table,
and 1 for the first level page table, so in total 6 frames, which are $6 \cdot 8KB = 48KB$. The fact htat most of the
table isn't used is crucial, each table points to 16MB ($2^{11}$ entries of size 8KB).
% subsection 4 (end)

\subsection{Moed A 2024}\label{sub:Moed A 2024} % (fold)
I'm not replicating the question here (it was written in Hebrew), however, here are the answers: \begin{itemize}
    \item false
    \item false
    \item true
    \item false
    \item false
    \item true
    \item false
    \item false
\end{itemize}
% subsection Moed A 2024 (end)

\subsection{Moed B 2024}\label{sub:Moed B 2024} % (fold)
I'm not replicating the question here (it was written in Hebrew), however, here are the answers: \begin{enumerate}
    \item We want to divide the size of the page, by the size of each entry (each row): $\displaystyle\frac{2^2 \cdot 2^{10}}{2^3} = 2^9 = 512$
    \item We want to first find out how many rows we have, which is the main memory, divided by the size of each page:
        \[
            \displaystyle\frac{64GB}{4KB} = \displaystyle\frac{2^{36}}{2^{12}} = 2^{24}
        \]
        So we need $2^{24}$ rows, and the size of each row is 8B, so we need overall: \[
            2^{24} \cdot 2^3 = 2^{27}B
        \]
    \item Main memory = 64GB = $2^{36}$B \\
        Page size = 4KB = $2^{12}$B \\
        Remaining bits = 36 - 12 = 24 \\
        We have 512 rows per page, which takes 9 bits, so = 24 - 9 = 15 \\
        To index these 9 bits of level 1, we need 9 bits of level 2 = 15 - 9 = 6 \\
        We theoretically need 9 bits here to index level 2, but we only have 6, which limits the size of level
        2 to be indexed by these 6 bits of level 3 = 6 - 6 = 9 \\
    Therefore, we have 3 levels in the table, as a minimum.
\end{enumerate}
% subsection Moed B 2024 (end)
% section Exam questiosn (end)

\end{document}
